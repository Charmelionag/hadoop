FROM ubuntu
MAINTAINER Iurie Muradu "muradu.iurie.1986@gmail.com"

RUN apt update && apt install -y wget ssh vim iputils-ping openjdk-8-jdk
RUN echo "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64" | tee -a /root/.bashrc
RUN /bin/bash -c "source /root/.bashrc"
RUN ssh-keygen -b 2048 -t rsa -f /root/.ssh/id_rsa -q -N ""
RUN touch /root/.ssh/authorized_keys && cat /root/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
RUN echo "Host localhost\n\tHostName 127.0.0.1\n\tStrictHostKeyChecking no\nHost 0.0.0.0\n\tHostName 0.0.0.0\n\tStrictHostKeyChecking no" | tee /root/.ssh/config
RUN sed -i 's/^#PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config
WORKDIR /root
RUN wget https://archive.apache.org/dist/hadoop/common/hadoop-2.6.5/hadoop-2.6.5.tar.gz
RUN tar -xzvf hadoop-2.6.5.tar.gz
RUN mv hadoop-2.6.5 hadoop
RUN rm hadoop-2.6.5.tar.gz
RUN echo "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n\
export HADOOP_HOME=/root/hadoop\n\
export PATH=\$HADOOP_HOME/bin:\$HADOOP_HOME/sbin:\$PATH\n\
export HADOOP_INSTALL=\$HADOOP_HOME\n\
export HADOOP_MAPRED_HOME=\$HADOOP_HOME\n\
export HADOOP_COMMON_HOME=\$HADOOP_HOME\n\
export HADOOP_HDFS_HOME=\$HADOOP_HOME\n\
export YARN_HOME=\$HADOOP_HOME\n\
export HADOOP_COMMON_LIB_NATIVE_DIR=\$HADOOP_HOME/lib/native\n\
export HADOOP_OPTS=\"-Djava.library.path=\$HADOOP_HOME/lib/native\"" | tee -a .bashrc
ENV PATH="${PATH}:/root/hadoop/sbin:/root/hadoop/bin"
RUN sed -i "s|export HADOOP_CONF_DIR=.*|export HADOOP_CONF_DIR=\${HADOOP_CONF_DIR:-\"/root/hadoop/etc/hadoop\"}|" hadoop/etc/hadoop/hadoop-env.sh
RUN sed -i "s/^export JAVA_HOME.*/export JAVA_HOME=\/usr\/lib\/jvm\/java-8-openjdk-amd64/" /root/hadoop/etc/hadoop/hadoop-env.sh
RUN echo "<configuration>\n\
\t<property>\n\
\t\t<name>fs.defaultFS</name>\n\
\t\t<value>hdfs://localhost:9000</value>\n\
\t</property>\n\
\t<property>\n\
\t\t<name>hadoop.tmp.dir</name>\n\
\t\t<value>/root/hadooptmpdata</value>\n\
\t</property>\n\
</configuration>" | tee hadoop/etc/hadoop/core-site.xml
RUN mkdir -p /root/hadooptmpdata
RUN echo "<configuration>\n\
\t<property>\n\
\t\t<name>dfs.replication</name>\n\
\t\t<value>1</value>\n\
\t</property>\n\
\t<property>\n\
\t\t<name>dfs.name.dir</name>\n\
\t\t<value>file:///root/hdfs/namenode</value>\n\
\t</property>\n\
\t<property>\n\
\t\t<name>dfs.data.dir</name>\n\
\t\t<value>file:///root/hdfs/datanode</value>\n\
\t</property>\n\
</configuration>" | tee hadoop/etc/hadoop/hdfs-site.xml
RUN mkdir -p hdfs/namenode && mkdir hdfs/datanode
RUN cp hadoop/etc/hadoop/mapred-site.xml.template hadoop/etc/hadoop/mapred-site.xml
RUN echo "<configuration>\n\
\t<property>\n\
\t\t<name>mapreduce.framework.name</name>\n\
\t\t<value>yarn</value>\n\
\t</property>\n\
</configuration>" | tee hadoop/etc/hadoop/mapred-site.xml
RUN echo "<configuration>\n\
\t<property>\n\
\t\t<name>mapreduceyarn.nodemanager.aux-services</name>\n\
\t\t<value>mapreduce_shuffle</value>\n\
\t</property>\n\
</configuration>" | tee hadoop/etc/hadoop/yarn-site.xml
RUN echo '#!/bin/bash' > deploy.sh
RUN echo "service ssh start\n\
hdfs namenode -format\n\
start-dfs.sh\n\
start-yarn.sh\n\
ping 0.0.0.0 > /dev/null" >> deploy.sh && chmod +x deploy.sh
EXPOSE 50070 8088
CMD ./deploy.sh
